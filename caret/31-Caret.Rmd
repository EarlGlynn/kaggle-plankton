---
title: "Caret Plankton Model"
author: "Earl F Glynn"
output: html_document
---

*****

```{r, cache=TRUE, comment=NA}
library(caret)
set.seed(37)
options(width=150)
```

```{r, cache=TRUE, comment=NA}
time.1 <- Sys.time()
format(time.1, "%Y-%m-%d-%H%M%S")
```

## Load raw TRAINING file

```{r, comment=NA}
load("../Features/plankton-train-wndchrm-skimage-features.Rdata", verbose=TRUE)
dim(train.features)
length(train.class)
```

## Setup parallel processing

```{r parallel, comment=NA}
library(doParallel)
rCluster <- makePSOCKcluster(6)  # Use 6 cores
registerDoParallel(rCluster)
```

## Remove Rows with NAs

For now kick out rows that have NAs. All of the NAs are from the skimage features and for some reason only affect class=1 with plenty of left-over rows for analysis.

```{r NAs, cache=TRUE, comment=NA}
sum(is.na(train.features))

countsColumnNA <- apply(train.features, 2, function(x) {sum(is.na(x))}) 
countsColumnNA[countsColumnNA > 0]

countsRowNA <- apply(train.features, 1, function(x) {sum(is.na(x))}) 
NArows <- countsRowNA > 0
countNArows <- sum(NArows)
countNArows
table(train.class[countsRowNA[NArows]])  # Why is only class 1 affected?

train.class    <- train.class[!NArows]
train.features <- train.features[!NArows,]
originalDim <- dim(train.features)
originalDim

table(train.class)

sum(is.na(train.features))
```

## Caret preprocessing

See 

* [Caret Pre-Processing](http://caret.r-forge.r-project.org/preprocess.html)
* [Pre-Processing of Predictors](http://www.inside-r.org/node/86978)
* [Building Predictive Models in R Using the caret Package](http://www.jstatsoft.org/v28/i05/paper)

### Remove near-zero variance predictors

```{r nearzero, cache=TRUE, comment=NA}
nzv <- nearZeroVar(train.features, saveMetrics=TRUE)
countNzv <- sum(nzv$nzv)
countNzv
nzv[nzv$nzv,]
train.features <- train.features[,!nzv$nzv]
dim(train.features)
```

### Remove variables with high correlation to others

```{r highcor, cache=TRUE, comment=NA}
cor.matrix <- cor(train.features)

cor.high.count <- sum(abs(cor.matrix[upper.tri(cor.matrix)]) > 0.99)
cor.high.count

# Range check
summary(cor.matrix[upper.tri(cor.matrix)])

COR.HIGH.CUTOFF <- 0.80
cor.high   <- findCorrelation(cor.matrix, cutoff=COR.HIGH.CUTOFF)
length(cor.high)

train.features <- train.features[, -cor.high]
dim(train.features)

# Repeat range check
cor.matrix <- cor(train.features)
summary(cor.matrix[upper.tri(cor.matrix)])
#boxplot(cor.matrix[upper.tri(cor.matrix)])
```

### Linear Dependencies
```{r lineardepend, cache=TRUE, comment=NA}
linearCombos <- findLinearCombos(train.features)
countLinearCombos <- length(linearCombos$remove)
countLinearCombos
train.features <- train.features[, -linearCombos$remove]
dim(train.features)
```

### Class Distance Calculations

Because of some of the small Plankton classes, this technique **cannot** be used without receiving this error:  

```
centroids <- classDist(as.factor(train.class), train.features)
"there must be more rows than columns for this class"
```

### Other Preprocessing

YeoJohnson is like BoxCox but can be used with zero and negative values.

Caret execution order:  Box-Cox/Yeo-Johnson/expoTrans, center, scale, range, imputation,
                        PCA/ICA, spatial sign
                        
Variations to try:  

1a. pca, thresh=0.95 or pcaComp=75

or

1b. ica, n.comp=3

2. spatial sign  (may help when there are outliers)                      

```{r carettrain,cache=TRUE, comment=NA}
PREPROC.METHOD <- c("center", "scale")

finalPreprocessDim <- dim(train.features)
finalPreprocessDim

trainPreProcessed <- preProcess(train.features, 
                                method=PREPROC.METHOD,
                                #thresh=0.75,
                                na.remove=FALSE,  # already removed
                                verbose=TRUE)
trainTransformed <- predict(trainPreProcessed, train.features)
transformedDim <- dim(trainTransformed)
transformedDim

rm(train.features)  # Save some memory

### Partition raw training data into a training and validation set.

```{r subset, cache=TRUE, comment=NA}
TRAIN.PERCENT <- 2/3
inTrainSetIndex <- createDataPartition(y=train.class, p=TRAIN.PERCENT, list=FALSE)

training        <- trainTransformed[ inTrainSetIndex,]
trainPlankton   <- as.factor(train.class)[inTrainSetIndex]

dim(training)
length(trainPlankton)

validation    <- trainTransformed[-inTrainSetIndex,]
validPlankton <- as.factor(train.class)[-inTrainSetIndex]

dim(validation)
length(validPlankton)
```

### Apply specified caret training method

See 

* Caret [Model Training and Tuning](http://topepo.github.io/caret/training.html)

* [Relationship between data splitting and trainControl](http://stackoverflow.com/questions/14968874/caret-relationship-between-data-splitting-and-traincontrol)

```{r caret, cache=TRUE, comment=NA}
#bootControl <- trainControl(method="boot", 
#                            number=3,  # use 200 or higher for final run
#                            verboseIter=TRUE)

# http://cran.r-project.org/web/packages/caret/vignettes/caret.pdf
crossValidationControl <- trainControl(method="repeatedcv", 
                                       repeats=3)

fit <- train(training, trainPlankton, 
             method="pls",   # Partial Least squares discriminant analysis (PLSDA)
             tunelength = 15,
             trControl=crossValidationControl,
             verbose=TRUE)
plot(fit)
summary(fit)
varImp(fit)

OutOfSample  <- predict(fit, newdata=validation)
confusion <- confusionMatrix(validPlankton, OutOfSample)

options(width=120)
confusion
```

### Summary info

Rows kicked out with NAs
```{r, comment=NA}
countNArows
```

Orignial feature matrix dim
```{r, comment=NA}
originalDim
```

Near-zero variance predictors removed
```{r, comment=NA}
sum(nzv$nzv)
```

High Correlation predictors
```{r, comment=NA}
COR.HIGH.CUTOFF
length(cor.high)
```

Linear Dependencies predictors removed
```{r, comment=NA}
length(linearCombos$remove)
```

Preprocess / Transformed Feature Matrix
```{r, comment=NA}
finalPreprocessDim
transformedDim
```               
Methods used
```{r, comment=NA}
PREPROC.METHOD
```

```{r, comment=NA}
stopCluster(rCluster)
```

*****

```{r, cache=TRUE, comment=NA}
time.2 <- Sys.time()
cat(sprintf("%.1f", as.numeric(difftime(time.2, time.1, units="secs"))), " secs\n")
```

*****

*efg* @EarlGlynn

`r format(Sys.time(), "%Y-%m-%d  %H%M")`
